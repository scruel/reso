#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯­ä¹‰æœç´¢æµ‹è¯•è„šæœ¬

ç”¨äºæµ‹è¯•å¯¼å…¥åˆ° PGVector çš„å•†å“æ•°æ®ï¼ŒéªŒè¯è¯­ä¹‰æœç´¢åŠŸèƒ½ã€‚

ä½¿ç”¨æ–¹æ³•:
    python test_semantic_search.py "æœç´¢æŸ¥è¯¢"
"""

import os
import sys
import logging
from typing import List, Dict
import psycopg2
from psycopg2.extras import RealDictCursor
import numpy as np
from transformers import AutoTokenizer, AutoModel
import torch

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SemanticSearcher:
    """è¯­ä¹‰æœç´¢å™¨"""
    
    def __init__(self, db_params: Dict[str, str], model_name: str = "Alibaba-NLP/gte-Qwen2-1.5B-instruct"):
        """åˆå§‹åŒ–æœç´¢å™¨
        
        Args:
            db_params: æ•°æ®åº“è¿æ¥å‚æ•°
            model_name: åµŒå…¥æ¨¡å‹åç§°
        """
        self.db_params = db_params
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½æ¨¡å‹
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True)
        self.model.to(self.device)
        self.model.eval()
        
        logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
    
    def encode_query(self, query: str) -> np.ndarray:
        """ç¼–ç æŸ¥è¯¢æ–‡æœ¬
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            æŸ¥è¯¢å‘é‡
        """
        with torch.no_grad():
            inputs = self.tokenizer(
                [query],
                padding=True,
                truncation=True,
                max_length=512,
                return_tensors='pt'
            ).to(self.device)
            
            outputs = self.model(**inputs)
            embedding = outputs.last_hidden_state[:, 0, :]
            embedding = torch.nn.functional.normalize(embedding, p=2, dim=1)
            
            return embedding.cpu().numpy()[0]
    
    def search(self, query: str, limit: int = 10) -> List[Dict]:
        """æ‰§è¡Œè¯­ä¹‰æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            limit: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # ç¼–ç æŸ¥è¯¢
        query_vector = self.encode_query(query)
        
        # è¿æ¥æ•°æ®åº“
        conn = psycopg2.connect(**self.db_params)
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        try:
            # æ‰§è¡Œè¯­ä¹‰æœç´¢
            search_sql = """
            SELECT 
                id,
                good_short_name,
                brand_name,
                price,
                catagory_full,
                sub_catagory,
                item_catagory,
                pic_url,
                LEFT(detail, 200) as detail_preview,
                1 - (embedding <=> %s) as similarity
            FROM goods 
            ORDER BY embedding <=> %s 
            LIMIT %s;
            """
            
            cursor.execute(search_sql, (query_vector.tolist(), query_vector.tolist(), limit))
            results = cursor.fetchall()
            
            return [dict(row) for row in results]
            
        finally:
            cursor.close()
            conn.close()
    
    def get_stats(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        conn = psycopg2.connect(**self.db_params)
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        try:
            # æ€»å•†å“æ•°
            cursor.execute("SELECT COUNT(*) as total_goods FROM goods;")
            total_goods = cursor.fetchone()['total_goods']
            
            # å“ç‰Œæ•°
            cursor.execute("SELECT COUNT(DISTINCT brand_name) as total_brands FROM goods;")
            total_brands = cursor.fetchone()['total_brands']
            
            # åˆ†ç±»æ•°
            cursor.execute("SELECT COUNT(DISTINCT catagory_full) as total_categories FROM goods;")
            total_categories = cursor.fetchone()['total_categories']
            
            return {
                'total_goods': total_goods,
                'total_brands': total_brands,
                'total_categories': total_categories
            }
            
        finally:
            cursor.close()
            conn.close()

def print_search_results(results: List[Dict], query: str):
    """æ‰“å°æœç´¢ç»“æœ
    
    Args:
        results: æœç´¢ç»“æœ
        query: æœç´¢æŸ¥è¯¢
    """
    print(f"\nğŸ” æœç´¢æŸ¥è¯¢: '{query}'")
    print(f"ğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³å•†å“\n")
    
    for i, result in enumerate(results, 1):
        similarity = result['similarity']
        print(f"#{i} [{similarity:.3f}] {result['good_short_name']}")
        print(f"   å“ç‰Œ: {result['brand_name']}")
        print(f"   ä»·æ ¼: Â¥{result['price']}")
        print(f"   åˆ†ç±»: {result['catagory_full']}")
        if result['detail_preview']:
            print(f"   è¯¦æƒ…: {result['detail_preview']}...")
        print(f"   å›¾ç‰‡: {result['pic_url']}")
        print()

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python test_semantic_search.py \"æœç´¢æŸ¥è¯¢\"")
        print("ç¤ºä¾‹: python test_semantic_search.py \"å……ç”µå®\"")
        return 1
    
    query = sys.argv[1]
    
    # æ•°æ®åº“è¿æ¥å‚æ•°
    db_params = {
        'host': os.getenv('DB_HOST', 'localhost'),
        'port': os.getenv('DB_PORT', '5432'),
        'database': os.getenv('DB_NAME', 'reso'),
        'user': os.getenv('DB_USER', 'postgres'),
        'password': os.getenv('DB_PASSWORD', 'password')
    }
    
    try:
        # åˆ›å»ºæœç´¢å™¨
        searcher = SemanticSearcher(db_params)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = searcher.get_stats()
        print(f"ğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡:")
        print(f"   æ€»å•†å“æ•°: {stats['total_goods']}")
        print(f"   å“ç‰Œæ•°: {stats['total_brands']}")
        print(f"   åˆ†ç±»æ•°: {stats['total_categories']}")
        
        # æ‰§è¡Œæœç´¢
        results = searcher.search(query, limit=5)
        
        # æ‰“å°ç»“æœ
        print_search_results(results, query)
        
        # æä¾›ä¸€äº›æœç´¢å»ºè®®
        if not results:
            print("ğŸ’¡ æœç´¢å»ºè®®:")
            print("   - å°è¯•ä½¿ç”¨æ›´é€šç”¨çš„å…³é”®è¯")
            print("   - æ£€æŸ¥æ‹¼å†™æ˜¯å¦æ­£ç¡®")
            print("   - å°è¯•ä½¿ç”¨å•†å“åˆ†ç±»æˆ–å“ç‰Œåç§°")
        
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())